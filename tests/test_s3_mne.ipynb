{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create empty mne-python raw object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=74, n_times=747750\n",
      "    Range : 0 ... 747749 =      0.000 ...  2990.996 secs\n",
      "Ready.\n",
      "False\n",
      "<class 'mne.io.array.array.RawArray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "# Create a simple RawArray\n",
    "sfreq = 250  # Sampling frequency\n",
    "ch_names = [f'EEG{d}' for d in range(1,75)]\n",
    "ch_types = [\"eeg\"] * 74\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "\n",
    "data = np.random.randn(74, 747750)  # 2 channels, 1000 samples\n",
    "raw = mne.io.RawArray(data, info)\n",
    "\n",
    "print(isinstance(raw, mne.io.Raw))  # True\n",
    "print(type(raw))  # <class 'mne.io.array.array.RawArray'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "braindecode call __getitem__ of mne.base.Raw, which then calls _getitem which calls _read_segment of BaseRaw. mne uses _read_segment to read a specific range of the file. We want to test whether S3 file via fsspec can be integrated\n",
    "It calls _read_segments_file of the BaseRaw class. Any subclass must implement this method. EEGLAB calls fiff reader function: mne/_fiff/utils.py#L200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to make edits to repo without having to restart notebook\n",
    "from eegdash import EEGDash\n",
    "from braindecode.datasets import BaseDataset, BaseConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling_frequency</th>\n",
       "      <th>nchans</th>\n",
       "      <th>ntimes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>747000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>738750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>741750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>736750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>738750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>747750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>736500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>738250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>739500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>741500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>743000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>744000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>743250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sampling_frequency  nchans  ntimes\n",
       "0                  250      74  742500\n",
       "1                  250      74  747000\n",
       "2                  250      74  740000\n",
       "3                  250      74  738750\n",
       "4                  250      74  741750\n",
       "5                  250      74  736750\n",
       "6                  250      74  749000\n",
       "7                  250      74  738750\n",
       "8                  250      74  747750\n",
       "9                  250      74  736500\n",
       "10                 250      74  738250\n",
       "11                 250      74  739500\n",
       "12                 250      74  749000\n",
       "13                 250      74  741500\n",
       "14                 250      74  743000\n",
       "15                 250      74  744000\n",
       "16                 250      74  742500\n",
       "17                 250      74  743250"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg = EEGDash()\n",
    "datasets = eeg.find({'dataset': 'ds002718'})\n",
    "datasets.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signalstore = EEGDash(\n",
    "    is_public=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://openneuro.org/ds002718/sub-002/eeg/sub-002_task-FaceRecognition_eeg.set\n"
     ]
    }
   ],
   "source": [
    "record = signalstore.find({'dataset': 'ds002718', 'subject': '002'})[0]\n",
    "sfreq = record['sampling_frequency']\n",
    "nchans = record['nchans']\n",
    "ntimes = record['ntimes']\n",
    "ch_names = record['channel_names']\n",
    "ch_types = record['channel_types']\n",
    "s3_path = signalstore.get_s3path(record)\n",
    "print(s3_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {'dataset': 'ds005511', 'subject': 'NDARUF236HM7'}\n",
    "datasets = []\n",
    "for record in signalstore.find(query):\n",
    "    sfreq = record['sampling_frequency']\n",
    "    nchans = record['nchans']\n",
    "    ntimes = record['ntimes']\n",
    "    ch_names = record['channel_names']\n",
    "    ch_types = record['channel_types']\n",
    "    s3_path = signalstore.get_s3path(record)\n",
    "    datasets.append(BaseDataset(RawEEGDash(s3_path, {'sfreq': sfreq, 'nchans': nchans, 'n_times': ntimes, 'ch_types': ch_types, 'ch_names': ch_names}, preload=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "integrate with braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegdash_braindecode = BaseConcatDataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.preprocessing import (\n",
    "    preprocess, Preprocessor, create_fixed_length_windows)\n",
    "windows_ds = create_fixed_length_windows(eegdash_braindecode, start_offset_samples=0, stop_offset_samples=None,\n",
    "        window_size_samples=1000,\n",
    "        window_stride_samples=1000, drop_last_window=True,\n",
    "        preload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3file s3://openneuro.org/ds005511/sub-NDARUF236HM7/eeg/sub-NDARUF236HM7_task-RestingState_eeg.set\n",
      "filecache ./.eegdash_cache/sub-NDARUF236HM7_task-RestingState_eeg.set\n",
      "s3file s3://openneuro.org/ds005511/sub-NDARUF236HM7/eeg/sub-NDARUF236HM7_task-symbolSearch_eeg.set\n",
      "filecache ./.eegdash_cache/sub-NDARUF236HM7_task-symbolSearch_eeg.set\n",
      "s3file s3://openneuro.org/ds005511/sub-NDARUF236HM7/eeg/sub-NDARUF236HM7_task-seqLearning6target_eeg.set\n",
      "filecache ./.eegdash_cache/sub-NDARUF236HM7_task-seqLearning6target_eeg.set\n",
      "s3file s3://openneuro.org/ds005511/sub-NDARUF236HM7/eeg/sub-NDARUF236HM7_task-surroundSupp_run-1_eeg.set\n",
      "filecache ./.eegdash_cache/sub-NDARUF236HM7_task-surroundSupp_run-1_eeg.set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3340652/2020391110.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  torch.tensor([windows_ds[w][0] for w in range(len(windows_ds))]).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1793, 129, 1000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.tensor([windows_ds[w][0] for w in range(len(windows_ds))]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
