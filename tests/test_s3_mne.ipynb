{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create empty mne-python raw object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=74, n_times=747750\n",
      "    Range : 0 ... 747749 =      0.000 ...  2990.996 secs\n",
      "Ready.\n",
      "False\n",
      "<class 'mne.io.array.array.RawArray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "# Create a simple RawArray\n",
    "sfreq = 250  # Sampling frequency\n",
    "ch_names = [f'EEG{d}' for d in range(1,75)]\n",
    "ch_types = [\"eeg\"] * 74\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "\n",
    "data = np.random.randn(74, 747750)  # 2 channels, 1000 samples\n",
    "raw = mne.io.RawArray(data, info)\n",
    "\n",
    "print(isinstance(raw, mne.io.Raw))  # True\n",
    "print(type(raw))  # <class 'mne.io.array.array.RawArray'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "braindecode call __getitem__ of mne.base.Raw, which then calls _getitem which calls _read_segment of BaseRaw. mne uses _read_segment to read a specific range of the file. We want to test whether S3 file via fsspec can be integrated\n",
    "It calls _read_segments_file of the BaseRaw class. Any subclass must implement this method. EEGLAB calls fiff reader function: mne/_fiff/utils.py#L200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to make edits to repo without having to restart notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "from eegdash import EEGDash\n",
    "from eegdash.data_utils import RawEEGDash\n",
    "from braindecode.datasets import BaseDataset, BaseConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signalstore = EEGDash(\n",
    "    is_public=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://openneuro.org/ds002718/sub-002/eeg/sub-002_task-FaceRecognition_eeg.set\n"
     ]
    }
   ],
   "source": [
    "record = signalstore.find({'dataset': 'ds002718', 'subject': '002'})[0]\n",
    "sfreq = record['sampling_frequency']\n",
    "nchans = record['nchans']\n",
    "ntimes = record['ntimes']\n",
    "ch_names = record['channel_names']\n",
    "ch_types = record['channel_types']\n",
    "s3_path = signalstore.get_s3path(record)\n",
    "print(s3_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {'dataset': 'ds005511', 'subject': 'NDARUF236HM7'}\n",
    "datasets = []\n",
    "for record in signalstore.find(query):\n",
    "    sfreq = record['sampling_frequency']\n",
    "    nchans = record['nchans']\n",
    "    ntimes = record['ntimes']\n",
    "    ch_names = record['channel_names']\n",
    "    ch_types = record['channel_types']\n",
    "    s3_path = signalstore.get_s3path(record)\n",
    "    datasets.append(BaseDataset(RawEEGDash(s3_path, {'sfreq': sfreq, 'nchans': nchans, 'n_times': ntimes, 'ch_types': ch_types, 'ch_names': ch_names}, preload=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "integrate with braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegdash_braindecode = BaseConcatDataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.preprocessing import (\n",
    "    preprocess, Preprocessor, create_fixed_length_windows)\n",
    "windows_ds = create_fixed_length_windows(eegdash_braindecode, start_offset_samples=0, stop_offset_samples=None,\n",
    "        window_size_samples=1000,\n",
    "        window_stride_samples=1000, drop_last_window=True,\n",
    "        preload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3file s3://openneuro.org/ds005511/sub-NDARUF236HM7/eeg/sub-NDARUF236HM7_task-RestingState_eeg.set\n",
      "filecache ./.eegdash_cache/sub-NDARUF236HM7_task-RestingState_eeg.set\n",
      "s3file s3://openneuro.org/ds005511/sub-NDARUF236HM7/eeg/sub-NDARUF236HM7_task-symbolSearch_eeg.set\n",
      "filecache ./.eegdash_cache/sub-NDARUF236HM7_task-symbolSearch_eeg.set\n",
      "s3file s3://openneuro.org/ds005511/sub-NDARUF236HM7/eeg/sub-NDARUF236HM7_task-seqLearning6target_eeg.set\n",
      "filecache ./.eegdash_cache/sub-NDARUF236HM7_task-seqLearning6target_eeg.set\n",
      "s3file s3://openneuro.org/ds005511/sub-NDARUF236HM7/eeg/sub-NDARUF236HM7_task-surroundSupp_run-1_eeg.set\n",
      "filecache ./.eegdash_cache/sub-NDARUF236HM7_task-surroundSupp_run-1_eeg.set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3340652/2020391110.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  torch.tensor([windows_ds[w][0] for w in range(len(windows_ds))]).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1793, 129, 1000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.tensor([windows_ds[w][0] for w in range(len(windows_ds))]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
