{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=74, n_times=747750\n",
      "    Range : 0 ... 747749 =      0.000 ...  2990.996 secs\n",
      "Ready.\n",
      "False\n",
      "<class 'mne.io.array.array.RawArray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "# Create a simple RawArray\n",
    "sfreq = 250  # Sampling frequency\n",
    "ch_names = [f'EEG{d}' for d in range(1,75)]\n",
    "ch_types = [\"eeg\"] * 74\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "\n",
    "data = np.random.randn(74, 747750)  # 2 channels, 1000 samples\n",
    "raw = mne.io.RawArray(data, info)\n",
    "\n",
    "print(isinstance(raw, mne.io.Raw))  # True\n",
    "print(type(raw))  # <class 'mne.io.array.array.RawArray'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "braindecode call __getitem__ of mne.base.Raw, which then calls _getitem which calls _read_segment of BaseRaw. mne uses _read_segment to read a specific range of the file. We want to test whether S3 file via fsspec can be integrated\n",
    "It calls _read_segments_file of the BaseRaw class. Any subclass must implement this method. EEGLAB calls fiff reader function: mne/_fiff/utils.py#L200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import s3fs\n",
    "import tempfile\n",
    "import os\n",
    "filesystem = s3fs.S3FileSystem(anon=True, client_kwargs={'region_name': 'us-east-2'})\n",
    "s3path = 's3://testspeedeegdash/sub-002_task-FaceRecognition_eeg.set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(delete=False, suffix='.set') as tmp:\n",
    "    # Download from S3 to temp file\n",
    "    with filesystem.open(s3path) as s3_file:\n",
    "        tmp.write(s3_file.read())\n",
    "    tmp_path = tmp.name\n",
    "    np.memmap(tmp_path)\n",
    "    # Clean up temp file\n",
    "    os.unlink(tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'r\\x00a\\x00w\\x00.\\x00f\\x00i\\x00f\\x00\\x00\\x00\\x0e\\x00\\x00\\x008\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x06\\x00\\x00\\x00nbchan\\x00\\x00\\x02\\x00\\x01\\x00J\\x00\\x00\\x00\\x0e\\x00\\x00\\x008\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x06\\x00\\x00\\x00trials\\x00\\x00\\x02\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x0e\\x00\\x00\\x000\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x04\\x00pnts\\x05\\x00\\x04\\x00\\xe6h\\x0b\\x00\\x0e\\x00\\x00\\x008\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00srate\\x00\\x00\\x00\\x02\\x00\\x01\\x00\\xfa\\x00\\x00\\x00\\x0e\\x00\\x00\\x008\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x04\\x00xmin\\t\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80\\x0e\\x00\\x00\\x008\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x04\\x00xmax\\t\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\xa2E\\xb6\\xf3\\xfd]\\xa7@\\x0e\\x00\\x00\\x00hG[\\x00\\x06\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\xe6h\\x0b\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00times\\x00\\x00\\x00\\t\\x00\\x00\\x000G[\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80\\x00\\x00\\x00\\x00\\x00\\x00\\x10@\\x00\\x00\\x00\\x00\\x00\\x00 @\\x00\\x00\\x00\\x00\\x00\\x00(@\\x00\\x00\\x00\\x00\\x00\\x000@\\x00\\x00\\x00\\x00\\x00\\x004@\\x00\\x00\\x00\\x00\\x00\\x008@\\x00\\x00\\x00\\x00\\x00\\x00<@\\x00\\x00\\x00\\x00\\x00\\x00@@\\x00\\x00\\x00\\x00\\x00\\x00B@\\x00\\x00\\x00\\x00\\x00\\x00D@\\x00\\x00\\x00\\x00\\x00\\x00F@\\x00\\x00\\x00\\x00\\x00\\x00H@\\x00\\x00\\x00\\x00\\x00\\x00J@\\x00\\x00\\x00\\x00\\x00\\x00L@\\x00\\x00\\x00\\x00\\x00\\x00N@\\x00\\x00\\x00\\x00\\x00\\x00P@\\x00\\x00\\x00\\x00\\x00\\x00Q@\\x00\\x00\\x00\\x00\\x00\\x00R@\\x00\\x00\\x00\\x00\\x00\\x00S@\\x00\\x00\\x00\\x00\\x00\\x00T@\\x00\\x00\\x00\\x00\\x00\\x00U@\\x00\\x00\\x00\\x00\\x00\\x00V@\\x00\\x00\\x00\\x00\\x00\\x00W@\\x00\\x00\\x00\\x00\\x00\\x00X@\\x00\\x00\\x00\\x00\\x00\\x00Y@\\x00\\x00\\x00\\x00\\x00\\x00Z@\\x00\\x00\\x00\\x00\\x00\\x00[@\\x00\\x00\\x00\\x00\\x00\\x00\\\\@\\x00\\x00\\x00\\x00\\x00\\x00]@\\x00\\x00\\x00\\x00\\x00\\x00^@\\x00\\x00\\x00\\x00\\x00\\x00_@\\x00\\x00\\x00\\x00\\x00\\x00`@\\x00\\x00\\x00\\x00\\x00\\x80`@\\x00\\x00\\x00\\x00\\x00\\x00a@\\x00\\x00\\x00\\x00\\x00\\x80a@\\x00\\x00\\x00\\x00\\x00\\x00b@\\x00\\x00\\x00\\x00\\x00\\x80b@\\x00\\x00\\x00\\x00\\x00\\x00c@\\x00\\x00\\x00\\x00\\x00\\x80c@\\x00\\x00\\x00\\x00\\x00\\x00d@\\x00\\x00\\x00\\x00\\x00\\x80d@\\x00\\x00\\x00\\x00\\x00\\x00e@\\x00\\x00\\x00\\x00\\x00\\x80e@\\x00\\x00\\x00\\x00\\x00\\x00f@\\x00\\x00\\x00\\x00\\x00\\x80f@\\x00\\x00\\x00\\x00\\x00\\x00g@\\x00\\x00\\x00\\x00\\x00\\x80g@\\x00\\x00\\x00\\x00\\x00\\x00h@\\x00\\x00\\x00\\x00\\x00\\x80h@\\x00\\x00\\x00\\x00\\x00\\x00i@\\x00\\x00\\x00\\x00\\x00\\x80i@\\x00\\x00\\x00\\x00\\x00\\x00j@\\x00\\x00\\x00\\x00\\x00\\x80j@\\x00\\x00\\x00\\x00\\x00\\x00k@\\x00\\x00\\x00\\x00\\x00\\x80k@\\x00\\x00\\x00\\x00\\x00\\x00l@\\x00\\x00\\x00\\x00\\x00\\x80l@\\x00\\x00\\x00\\x00\\x00\\x00m@\\x00\\x00\\x00\\x00\\x00\\x80m@\\x00\\x00\\x00\\x00\\x00\\x00n@\\x00\\x00\\x00\\x00\\x00\\x80n@\\x00\\x00\\x00\\x00\\x00\\x00o@\\x00\\x00\\x00\\x00\\x00\\x80o@\\x00\\x00\\x00\\x00\\x00\\x00p@\\x00\\x00\\x00\\x00\\x00@p@\\x00\\x00\\x00\\x00\\x00\\x80p@\\x00\\x00\\x00\\x00\\x00\\xc0p@\\x00\\x00\\x00\\x00\\x00\\x00q@\\x00\\x00\\x00\\x00\\x00@q@\\x00\\x00\\x00\\x00\\x00\\x80q@'\n"
     ]
    }
   ],
   "source": [
    "start_byte = 1024\n",
    "stop_byte = 1024 + 1024\n",
    "with filesystem.open(s3path) as s3_file:\n",
    "    s3_file.seek(start_byte)\n",
    "    data = s3_file.read(stop_byte - start_byte if stop_byte else None)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def _mult_cal_one(data_view, one, idx, cals, mult):\n",
    "    \"\"\"Take a chunk of raw data, multiply by mult or cals, and store.\"\"\"\n",
    "    one = np.asarray(one, dtype=data_view.dtype)\n",
    "    assert data_view.shape[1] == one.shape[1], (\n",
    "        data_view.shape[1],\n",
    "        one.shape[1],\n",
    "    )  # noqa: E501\n",
    "    if mult is not None:\n",
    "        assert mult.ndim == one.ndim == 2\n",
    "        data_view[:] = mult @ one[idx]\n",
    "    else:\n",
    "        assert cals is not None\n",
    "        if isinstance(idx, slice):\n",
    "            data_view[:] = one[idx]\n",
    "        else:\n",
    "            # faster than doing one = one[idx]\n",
    "            np.take(one, idx, axis=0, out=data_view)\n",
    "        data_view *= cals\n",
    "\n",
    "def _read_segments_file(\n",
    "    filesystem,\n",
    "    s3path,\n",
    "    # data,\n",
    "    # idx,\n",
    "    # fi,\n",
    "    start,\n",
    "    stop,\n",
    "    # cals,\n",
    "    # mult,\n",
    "    dtype,\n",
    "    n_channels=None,\n",
    "    offset=0,\n",
    "    trigger_ch=None,\n",
    "):\n",
    "    \"\"\"Read a chunk of raw data.\"\"\"\n",
    "    n_bytes = np.dtype(dtype).itemsize\n",
    "    # data_offset and data_left count data samples (channels x time points),\n",
    "    # not bytes.\n",
    "    data_offset = n_channels * start * n_bytes + offset # in bytes\n",
    "    data_left = (stop - start) * n_channels # in samples not bytes\n",
    "\n",
    "    # Read up to 100 MB of data at a time, block_size is in data samples\n",
    "    block_size = ((int(100e6) // n_bytes) // n_channels) * n_channels\n",
    "    block_size = min(data_left, block_size)\n",
    "    with filesystem.open(s3path) as fid:\n",
    "        fid.seek(data_offset)\n",
    "        # extract data in chunks\n",
    "        for sample_start in np.arange(0, data_left, block_size) // n_channels:\n",
    "            count = min(block_size, data_left - sample_start * n_channels)\n",
    "            # block = np.fromfile(fid, dtype, count)\n",
    "            block = fid.read(count)\n",
    "            block_size = sys.getsizeof(block)\n",
    "            print(block_size, count)\n",
    "            if block_size != count:\n",
    "                raise RuntimeError(\n",
    "                    f\"Incorrect number of samples ({block.size} != {count}), please \"\n",
    "                    \"report this error to MNE-Python developers\"\n",
    "                )\n",
    "            block = block.reshape(n_channels, -1, order=\"F\")\n",
    "            n_samples = block.shape[1]  # = count // n_channels\n",
    "            sample_stop = sample_start + n_samples\n",
    "            if trigger_ch is not None:\n",
    "                stim_ch = trigger_ch[start:stop][sample_start:sample_stop]\n",
    "                block = np.vstack((block, stim_ch))\n",
    "            # data_view = data[:, sample_start:sample_stop]\n",
    "            # _mult_cal_one(data_view, block, idx, cals, mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73811 73778\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m_read_segments_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m74\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 57\u001b[0m, in \u001b[0;36m_read_segments_file\u001b[0;34m(filesystem, s3path, start, stop, dtype, n_channels, offset, trigger_ch)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(block_size, count)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block_size \u001b[38;5;241m!=\u001b[39m count:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m---> 57\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect number of samples (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreport this error to MNE-Python developers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m     )\n\u001b[1;32m     60\u001b[0m block \u001b[38;5;241m=\u001b[39m block\u001b[38;5;241m.\u001b[39mreshape(n_channels, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m block\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# = count // n_channels\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "_read_segments_file(filesystem, s3path, 3, 1000, np.single, n_channels=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
