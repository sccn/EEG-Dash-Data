{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to make edits to repo without having to restart notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from eegdash import EEGDash\n",
    "from braindecode.datasets import BaseDataset, BaseConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('677db70295291b67a99cada1'), 'schema_ref': 'eeg_signal', 'data_name': 'ds002718_sub-014_task-FaceRecognition_eeg.set', 'dataset': 'ds002718', 'bidspath': 'ds002718/sub-014/eeg/sub-014_task-FaceRecognition_eeg.set', 'subject': '014', 'task': 'FaceRecognition', 'session': '', 'run': '', 'sampling_frequency': 250, 'modality': 'EEG', 'has_file': True, 'version_timestamp': 0, 'time_of_save': 1738946443346607, 'time_of_removal': None, 'nchans': 74, 'ntimes': 742500, 'channel_types': ['EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'HEOG', 'VEOG', 'ECG', 'ECG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG'], 'channel_names': ['EEG001', 'EEG002', 'EEG003', 'EEG004', 'EEG005', 'EEG006', 'EEG007', 'EEG008', 'EEG009', 'EEG010', 'EEG011', 'EEG012', 'EEG013', 'EEG014', 'EEG015', 'EEG016', 'EEG017', 'EEG018', 'EEG019', 'EEG020', 'EEG021', 'EEG022', 'EEG023', 'EEG024', 'EEG025', 'EEG026', 'EEG027', 'EEG028', 'EEG029', 'EEG030', 'EEG031', 'EEG032', 'EEG033', 'EEG034', 'EEG035', 'EEG036', 'EEG037', 'EEG038', 'EEG039', 'EEG040', 'EEG041', 'EEG042', 'EEG043', 'EEG044', 'EEG045', 'EEG046', 'EEG047', 'EEG048', 'EEG049', 'EEG050', 'EEG051', 'EEG052', 'EEG053', 'EEG054', 'EEG055', 'EEG056', 'EEG057', 'EEG058', 'EEG059', 'EEG060', 'EEG061', 'EEG062', 'EEG063', 'EEG064', 'EEG065', 'EEG066', 'EEG067', 'EEG068', 'EEG069', 'EEG070', 'EEG071', 'EEG072', 'EEG073', 'EEG074']}\n"
     ]
    }
   ],
   "source": [
    "eeg = EEGDash(is_public=False)\n",
    "# eeg.update_noref({'data_name': record['data_name']})\n",
    "datasets = eeg.findrecord({'dataset': 'ds002718'})\n",
    "print(datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_name': 'test2', 'dataset': 'test', 'bidspath': 'test', 'subject': 'test'}\n"
     ]
    }
   ],
   "source": [
    "record = {\n",
    "    'data_name': 'test2',\n",
    "    'dataset': 'test',\n",
    "    'bidspath': 'test',\n",
    "    'subject': 'test',\n",
    "}\n",
    "eeg.addnoref(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from eegdash.data_utils import BIDSDataset\n",
    "bidsdataset = BIDSDataset('/mnt/nemar/openneuro', 'ds002718')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/mnt/nemar/openneuro/ds002718/sub-014/eeg/sub-014_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-012/eeg/sub-012_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-015/eeg/sub-015_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-008/eeg/sub-008_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-006/eeg/sub-006_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-013/eeg/sub-013_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-004/eeg/sub-004_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-016/eeg/sub-016_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-002/eeg/sub-002_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-018/eeg/sub-018_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-007/eeg/sub-007_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-010/eeg/sub-010_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-017/eeg/sub-017_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-003/eeg/sub-003_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-011/eeg/sub-011_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-005/eeg/sub-005_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-009/eeg/sub-009_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-019/eeg/sub-019_task-FaceRecognition_eeg.set'],\n",
       "      dtype='<U78')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidsdataset.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TaskName': 'FaceRecognition',\n",
       " 'TaskDescription': \"Subjects viewed stimuli on a screen during six, 7.5 minute runs. The stimuli were photographs of either a famous face (known to most of British or a scrambled face, and appeared for a random duration between 800 and 1,000 ms. Subjects were instructed to fixate centrally throughout the experiment. To ensure attention to each stimulus, participants were asked to press one of two keys with either their left or right index finger (assignment counter-balanced across participants). Their key-press was based on how symmetric they regarded each image: pressing one or the other key depending whether they thought the image was 'more' or 'less symmetric' than average.\",\n",
       " 'InstitutionAddress': '15 Chaucer Road, Cambridge, UK',\n",
       " 'InstitutionName': 'MRC Cognition & Brain Sciences Unit',\n",
       " 'EEGReference': 'nose',\n",
       " 'EEGGround': 'left collar bone',\n",
       " 'SamplingFrequency': 250,\n",
       " 'PowerLineFrequency': 50,\n",
       " 'SoftwareFilters': {'LowPassFilter': {'cutoff': '350 (Hz)'}},\n",
       " 'EEGPlacementScheme': 'extended 10-10% system',\n",
       " 'CapManufacturer': 'Easycap',\n",
       " 'EEGChannelCount': 70,\n",
       " 'EOGChannelCount': 2,\n",
       " 'RecordingType': 'continuous',\n",
       " 'MiscChannelCount': 4,\n",
       " 'RecordingDuration': 2973,\n",
       " 'ECGChannelCount': 0,\n",
       " 'EMGChannelCount': 0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidsdataset.eeg_json('/mnt/nemar/openneuro/ds002718/sub-019/eeg/sub-019_task-FaceRecognition_eeg.set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/mnt/nemar/openneuro/ds002718/sub-019/eeg/sub-019_task-FaceRecognition_eeg.json')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidsdataset.get_bids_metadata_files('/mnt/nemar/openneuro/ds002718/sub-019/eeg/sub-019_task-FaceRecognition_eeg.set', 'eeg.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/mnt/nemar/openneuro/ds002718/participants.tsv')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidsdataset.get_bids_metadata_files('/mnt/nemar/openneuro/ds002718/sub-019/eeg/sub-019_task-FaceRecognition_eeg.set', 'participants.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
