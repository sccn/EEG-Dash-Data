{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to make edits to repo without having to restart notebook\n",
    "from eegdash import EEGDash\n",
    "from braindecode.datasets import BaseDataset, BaseConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling_frequency</th>\n",
       "      <th>nchans</th>\n",
       "      <th>ntimes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>747000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>738750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>741750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>736750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>738750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>747750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>736500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>738250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>739500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>741500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>743000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>744000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>250</td>\n",
       "      <td>74</td>\n",
       "      <td>743250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sampling_frequency  nchans  ntimes\n",
       "0                  250      74  742500\n",
       "1                  250      74  747000\n",
       "2                  250      74  740000\n",
       "3                  250      74  738750\n",
       "4                  250      74  741750\n",
       "5                  250      74  736750\n",
       "6                  250      74  749000\n",
       "7                  250      74  738750\n",
       "8                  250      74  747750\n",
       "9                  250      74  736500\n",
       "10                 250      74  738250\n",
       "11                 250      74  739500\n",
       "12                 250      74  749000\n",
       "13                 250      74  741500\n",
       "14                 250      74  743000\n",
       "15                 250      74  744000\n",
       "16                 250      74  742500\n",
       "17                 250      74  743250"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg = EEGDash()\n",
    "datasets = eeg.find({'dataset': 'ds002718'})\n",
    "datasets.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from eegdash.data_utils import BIDSDataset\n",
    "bidsdataset = BIDSDataset('/mnt/nemar/openneuro', 'ds002718')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/mnt/nemar/openneuro/ds002718/sub-014/eeg/sub-014_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-012/eeg/sub-012_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-015/eeg/sub-015_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-008/eeg/sub-008_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-006/eeg/sub-006_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-013/eeg/sub-013_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-004/eeg/sub-004_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-016/eeg/sub-016_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-002/eeg/sub-002_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-018/eeg/sub-018_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-007/eeg/sub-007_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-010/eeg/sub-010_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-017/eeg/sub-017_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-003/eeg/sub-003_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-011/eeg/sub-011_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-005/eeg/sub-005_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-009/eeg/sub-009_task-FaceRecognition_eeg.set',\n",
       "       '/mnt/nemar/openneuro/ds002718/sub-019/eeg/sub-019_task-FaceRecognition_eeg.set'],\n",
       "      dtype='<U78')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidsdataset.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TaskName': 'FaceRecognition',\n",
       " 'TaskDescription': \"Subjects viewed stimuli on a screen during six, 7.5 minute runs. The stimuli were photographs of either a famous face (known to most of British or a scrambled face, and appeared for a random duration between 800 and 1,000 ms. Subjects were instructed to fixate centrally throughout the experiment. To ensure attention to each stimulus, participants were asked to press one of two keys with either their left or right index finger (assignment counter-balanced across participants). Their key-press was based on how symmetric they regarded each image: pressing one or the other key depending whether they thought the image was 'more' or 'less symmetric' than average.\",\n",
       " 'InstitutionAddress': '15 Chaucer Road, Cambridge, UK',\n",
       " 'InstitutionName': 'MRC Cognition & Brain Sciences Unit',\n",
       " 'EEGReference': 'nose',\n",
       " 'EEGGround': 'left collar bone',\n",
       " 'SamplingFrequency': 250,\n",
       " 'PowerLineFrequency': 50,\n",
       " 'SoftwareFilters': {'LowPassFilter': {'cutoff': '350 (Hz)'}},\n",
       " 'EEGPlacementScheme': 'extended 10-10% system',\n",
       " 'CapManufacturer': 'Easycap',\n",
       " 'EEGChannelCount': 70,\n",
       " 'EOGChannelCount': 2,\n",
       " 'RecordingType': 'continuous',\n",
       " 'MiscChannelCount': 4,\n",
       " 'RecordingDuration': 2973,\n",
       " 'ECGChannelCount': 0,\n",
       " 'EMGChannelCount': 0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidsdataset.eeg_json('/mnt/nemar/openneuro/ds002718/sub-019/eeg/sub-019_task-FaceRecognition_eeg.set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/mnt/nemar/openneuro/ds002718/sub-019/eeg/sub-019_task-FaceRecognition_eeg.json')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidsdataset.get_bids_metadata_files('/mnt/nemar/openneuro/ds002718/sub-019/eeg/sub-019_task-FaceRecognition_eeg.set', 'eeg.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/mnt/nemar/openneuro/ds002718/participants.tsv')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidsdataset.get_bids_metadata_files('/mnt/nemar/openneuro/ds002718/sub-019/eeg/sub-019_task-FaceRecognition_eeg.set', 'participants.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
